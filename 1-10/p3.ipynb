{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54eabed2",
   "metadata": {},
   "source": [
    "# Pregunta 3\n",
    "Eliminar filas duplicadas basadas en columnas específicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f04c58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51817c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .appName(\"Pregunta3\")\\\n",
    "    .getOrCreate()\n",
    "# df_employees_duplicates\n",
    "df_ed = spark.read.csv('./datasets/employees_duplicates.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0d078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"Name\",\"Age\",\"Gender\",\"Department\",\"Salary\",\"Joining\",\"Date\",\n",
    "       \"Performance\",\"Score\",\"Location\",\"Session\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9434594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------+----------+------+----------+----+-----------+--------+-----------+-------+\n",
      "|                Name|Age|Gender|Department|Salary|   Joining|Date|Performance|   Score|   Location|Session|\n",
      "+--------------------+---+------+----------+------+----------+----+-----------+--------+-----------+-------+\n",
      "|           Eric York| 34|  Male|        HR|  3397|2022-06-25| 4.0|          2|  Active|Los Angeles|Evening|\n",
      "|       Mario Jackson| 43|  Male|        IT|  8563|2017-12-28| 4.0|         11|  Active|Los Angeles|  Night|\n",
      "|Mrs. Kimberly Woo...| 48|Female|     Sales|  7287|2019-03-06| 1.0|          9|  Active|Los Angeles|  Night|\n",
      "|       Briana Martin| 59|  Male|     Sales|  4496|2023-05-22| 1.0|         20|Inactive|   New York|  Night|\n",
      "|    Valerie Guerrero| 23|  Male|        HR|  6253|2023-09-21| 4.0|         14|  Active|Los Angeles|  Night|\n",
      "|    Monica Henderson| 39|  Male|        IT|  7250|2016-07-11| 4.0|          1|  Active|    Chicago|Morning|\n",
      "|        James Melton| 46| Other|     Sales|  6746|2019-07-31| 5.0|         16|Inactive|Los Angeles|  Night|\n",
      "|       Gabriel Weber| 32|  Male|        HR|  2759|2016-05-10| 5.0|          7|Inactive|Los Angeles|Evening|\n",
      "|        Emily Martin| 58|  Male|     Sales|  4038|2020-09-06| 3.0|         13|  Active|Los Angeles|Evening|\n",
      "|         Tammy Smith| 30|Female|     Sales|  2087|2015-01-09| 5.0|          6|Inactive|Los Angeles|Morning|\n",
      "+--------------------+---+------+----------+------+----------+----+-----------+--------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple\n",
    "df_clean = df_ed.dropDuplicates(columnas)\n",
    "df_clean2 = df_ed.dropDuplicates(['Name','Department','Joining'])\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93ee7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows Functions\n",
    "from pyspark.sql.window import Window \n",
    "window_spec = Window.partitionBy(['Name', 'Department']).orderBy(F.col(\"Joining\").desc()) \n",
    "df_clean_wf = df_ed.withColumn(\"row_num\", F.row_number().over(window_spec)) \\\n",
    "              .filter(F.col(\"row_num\") == 1) \\\n",
    "              .drop(\"row_num\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99c59659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de filas originales: 1274\n",
      "Cantidad de filas después de eliminar duplicados (método simple): 1000\n",
      "Cantidad de filas después de eliminar duplicados (método con funciones de ventana): 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de filas originales:\", df_ed.count())\n",
    "print(\"Cantidad de filas después de eliminar duplicados (método simple):\", df_clean.count())\n",
    "print(\"Cantidad de filas después de eliminar duplicados (método con funciones de ventana):\", df_clean_wf.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
