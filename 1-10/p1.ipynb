{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d459122c",
   "metadata": {},
   "source": [
    "## Pregunta 1\n",
    "Contar la frecuencia de cada palabra e imprimir las N palabras mas comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedf3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18060c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 03:06:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:14:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:14:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:14:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:15:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:16:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:17:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:18:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:19:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:20:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:21:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:22:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:20 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:30 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:40 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:23:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:24:00 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:24:10 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56) ~[spark-common-utils_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [?:?]\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [?:?]\n",
      "\tat java.lang.Thread.run(Unknown Source) [?:?]\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@9ba3e28f181c:46091\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86) ~[scala-library-2.12.18.jar:?]\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31) ~[spark-core_2.12-3.5.0.jar:3.5.0]\n",
      "\t... 8 more\n",
      "25/10/24 03:24:10 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Pregunta1\").getOrCreate()\n",
    "file = spark.read.text(\"./1342-0.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
